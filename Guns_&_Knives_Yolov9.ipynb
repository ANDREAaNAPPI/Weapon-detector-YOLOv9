{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP"
      ],
      "metadata": {
        "id": "tJTe45tqCuqo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HI9MXSvU825u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bd38b2-bd26-4c41-ee5a-6c9021b63638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount (\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making sure GPU is available\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "8e4JY-6ABA4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da44e08a-8866-4a4c-f4e0-cf96dfc7e487"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  4 13:51:48 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the data\n",
        "train_img_path = \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/train/images\"\n",
        "train_lab_path = \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/train/labels\"\n",
        "val_img_path = \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/valid/images\"\n",
        "val_lab_path = \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/valid/labels\"\n",
        "test_img_path = \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/test/images\"\n",
        "test_lab_path = \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/test/labels\"\n"
      ],
      "metadata": {
        "id": "NXG2-GZHXT8u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entering the folder where I'm storing my project\n",
        "%cd /content/drive/MyDrive/My projects/Guns & Knives YOLOv9\n",
        "\n",
        "# cloning the yolov9 github report in my folder\n",
        "!git clone https://github.com/WongKinYiu/yolov9.git\n",
        "\n",
        "#entering the imported folder\n",
        "%cd yolov9\n",
        "\n",
        "#installing the requirements\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "YrUfKpNZB486"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading pre-trained weights (on coco dataset) in pytorch model file (pt)\n",
        "\n",
        "# regular architectue c variant (lighter)\n",
        "!wget -P \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/pre-trained models\" https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
        "# regular architecture e variant (heavier but more accurate)\n",
        "!wget -P \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/pre-trained models\" https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n",
        "# gelan architecture c variant\n",
        "!wget -P \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/pre-trained models\" https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n",
        "# gelan architecture e variant\n",
        "!wget -P \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/pre-trained models\" https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt\n"
      ],
      "metadata": {
        "id": "X_TzuLaUZmAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ],
      "metadata": {
        "id": "l-ysWqfUD6A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For more params check out https://github.com/WongKinYiu/yolov9/blob/main/train.py\n",
        "# in /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/data/hyps/hyp.scratch-high.yaml:\n",
        " # copy_paste parameter has been changed to 0.0 (from 0.3)\n",
        " # flipupd to 0.2 from 0.0\n",
        " # degreesb to 0.2 from 0.0\n",
        "\n",
        "!python train.py \\\n",
        "--batch 16 --epochs 35 --img 640 --device 0 --min-items 0 \\\n",
        "--data \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/data.yaml\" \\\n",
        "--weights \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/pre-trained models/gelan-c.pt\" \\\n",
        "--cfg \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/models/detect/gelan-c.yaml\" \\\n",
        "--hyp \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/data/hyps/hyp.scratch-high.yaml\" \\\n",
        "--project \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info\" \\\n",
        "--name insights \\\n",
        "--save-period 5\n",
        "\n",
        "# 16 batches (would have loved to try 64, but had to settle for the highest possible given my GPU memory)\n",
        "# 35 eopchs (would have loved to get at least 50, but colab has limited GPU resources)\n",
        "# images are resized to 640x640\n",
        "# GPU device (0) is used\n",
        "# 0 anchor boxes (min) to detect an object\n",
        "# gelan c weights\n",
        "# saved the model every 5 epochs (other than the best model in the end)\n"
      ],
      "metadata": {
        "id": "y8ZRHXhTcArZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Because of GPU limits, I couldn't train the whole model in one go, so I split the training in 4 parts.\n",
        "# This is part 2, starting the training with the best weights coming from part 1.\n",
        "\n",
        "!python train.py \\\n",
        "--batch 16 --epochs 35 --img 640 --device 0 --min-items 0 \\\n",
        "--data \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/data.yaml\" \\\n",
        "--weights \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights/weights/best.pt\" \\\n",
        "--cfg \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/models/detect/gelan-c.yaml\" \\\n",
        "--hyp \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/data/hyps/hyp.scratch-high.yaml\" \\\n",
        "--project \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info\" \\\n",
        "--name insights_2 \\\n",
        "--save-period 5\n",
        "\n"
      ],
      "metadata": {
        "id": "6Rk0zblSbJBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is part 3, starting the training with the best weights coming from part 2.\n",
        "\n",
        "!python train.py \\\n",
        "--batch 16 --epochs 35 --img 640 --device 0 --min-items 0 \\\n",
        "--data \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/data.yaml\" \\\n",
        "--weights \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_2/weights/best.pt\" \\\n",
        "--cfg \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/models/detect/gelan-c.yaml\" \\\n",
        "--hyp \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/data/hyps/hyp.scratch-high.yaml\" \\\n",
        "--project \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info\" \\\n",
        "--name insights_3 \\\n",
        "--save-period 5\n"
      ],
      "metadata": {
        "id": "CPDtGaEbMr4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is part 4, starting the training with the best weights coming from part 3.\n",
        "\n",
        "!python train.py \\\n",
        "--batch 16 --epochs 35 --img 640 --device 0 --min-items 0 \\\n",
        "--data \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/data.yaml\" \\\n",
        "--weights \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_3/weights/best.pt\" \\\n",
        "--cfg \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/models/detect/gelan-c.yaml\" \\\n",
        "--hyp \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/data/hyps/hyp.scratch-high.yaml\" \\\n",
        "--project \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info\" \\\n",
        "--name insights_4 \\\n",
        "--save-period 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTaKKIrVTLXJ",
        "outputId": "20caef67-d80f-48c1-ab32-21a650e9bb8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-04 13:57:58.851421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-04 13:57:58.872205: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-04 13:57:58.878159: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-04 13:57:58.892652: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-04 13:58:00.139231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_3/weights/best.pt, cfg=/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/models/detect/gelan-c.yaml, data=/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/data.yaml, hyp=/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/data/hyps/hyp.scratch-high.yaml, epochs=35, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info, name=insights_4, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=5, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "/bin/sh: 1: Knives: not found\n",
            "fatal: cannot change to '/content/drive/MyDrive/My': No such file or directory\n",
            "YOLO ðŸš€ 2024-5-11 Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.2, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.2, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info', view at http://localhost:6006/\n",
            "/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/train.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(weights, map_location='cpu')  # load checkpoint to CPU to avoid CUDA memory leak\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            "  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            "  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            "  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
            " 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
            " 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
            " 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 22      [15, 18, 21]  1   5492182  models.yolo.DDetect                     [2, [256, 512, 512]]          \n",
            "gelan-c summary: 621 layers, 25438614 parameters, 25438598 gradients, 103.2 GFLOPs\n",
            "\n",
            "Transferred 937/937 items from /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_3/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/train/labels.cache... 4409 images, 20 backgrounds, 0 corrupt: 100% 4409/4409 [00:00<?, ?it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/valid/labels.cache... 1043 images, 7 backgrounds, 0 corrupt: 100% 1043/1043 [00:00<?, ?it/s]\n",
            "Plotting labels to /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_42/labels.jpg... \n",
            "/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/train.py:244: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_42\u001b[0m\n",
            "Starting training for 35 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/276 [00:00<?, ?it/s]/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/train.py:302: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/34      10.8G      0.774     0.7826      1.168         37        640:   0% 1/276 [00:15<1:08:59, 15.05s/it]/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/train.py:302: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/34      10.9G     0.8314     0.6896      1.186         41        640: 100% 276/276 [04:17<00:00,  1.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:27<00:00,  1.22it/s]\n",
            "                   all       1043       1203      0.931      0.884      0.951      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/34      12.5G     0.8464     0.7193      1.193         20        640: 100% 276/276 [03:59<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.35it/s]\n",
            "                   all       1043       1203      0.921      0.869      0.939      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/34      12.5G     0.8831     0.7774      1.212         27        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.34it/s]\n",
            "                   all       1043       1203      0.898      0.838      0.926      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/34      12.5G      0.945     0.8845       1.27         18        640: 100% 276/276 [03:54<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.31it/s]\n",
            "                   all       1043       1203      0.893       0.82      0.908      0.659\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/34      12.5G     0.9782     0.9417      1.286         15        640: 100% 276/276 [03:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.28it/s]\n",
            "                   all       1043       1203      0.861       0.84      0.908      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/34      12.5G     0.9869      0.926      1.289         22        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.30it/s]\n",
            "                   all       1043       1203       0.88       0.83       0.91       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/34      12.5G     0.9734      0.935      1.294         25        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.31it/s]\n",
            "                   all       1043       1203      0.908      0.814      0.912      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/34        13G     0.9807     0.9272      1.298         29        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.31it/s]\n",
            "                   all       1043       1203      0.914      0.802      0.895      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/34        13G     0.9681     0.9109      1.279         21        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.29it/s]\n",
            "                   all       1043       1203      0.892      0.824      0.908      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/34        13G     0.9744     0.9113      1.277         29        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.32it/s]\n",
            "                   all       1043       1203      0.884       0.84      0.917      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/34        13G     0.9562     0.8883      1.277         19        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.35it/s]\n",
            "                   all       1043       1203      0.891      0.855      0.914      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/34        13G     0.9553     0.8795      1.272         32        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.35it/s]\n",
            "                   all       1043       1203      0.884       0.87      0.919       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/34        13G     0.9352     0.8458      1.252         27        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.31it/s]\n",
            "                   all       1043       1203      0.901      0.821      0.917      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/34        13G       0.94     0.8689      1.264         27        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.30it/s]\n",
            "                   all       1043       1203      0.905      0.847      0.933      0.689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/34        13G     0.9251     0.8635      1.254         32        640: 100% 276/276 [03:54<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.33it/s]\n",
            "                   all       1043       1203      0.903      0.839      0.922       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/34        13G     0.9264     0.8234      1.253         30        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.35it/s]\n",
            "                   all       1043       1203      0.908      0.847       0.93        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/34        13G     0.8984     0.8035      1.229         24        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.35it/s]\n",
            "                   all       1043       1203      0.918       0.86      0.932      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/34        13G     0.9033     0.8051      1.234         22        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.31it/s]\n",
            "                   all       1043       1203       0.92      0.857      0.934      0.704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/34        13G     0.9015     0.7996      1.225         25        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.31it/s]\n",
            "                   all       1043       1203      0.911      0.866      0.935       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/34        13G     0.9026     0.7945      1.227         21        640: 100% 276/276 [03:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.31it/s]\n",
            "                   all       1043       1203      0.923      0.863      0.941       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/34        13G     0.8878     0.7784      1.226         28        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.34it/s]\n",
            "                   all       1043       1203      0.927      0.863       0.94      0.715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/34        13G     0.8754     0.7596      1.212         36        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.35it/s]\n",
            "                   all       1043       1203      0.931      0.857      0.938      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/34        13G     0.8676     0.7517       1.21         23        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.33it/s]\n",
            "                   all       1043       1203       0.91      0.875       0.94      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/34        13G     0.8566     0.7315      1.194         27        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.33it/s]\n",
            "                   all       1043       1203      0.933      0.865      0.945      0.723\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/34        13G     0.8604     0.7368      1.208         23        640: 100% 276/276 [03:52<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.29it/s]\n",
            "                   all       1043       1203      0.932      0.868      0.947      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/34        13G     0.8331     0.7137      1.181         23        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.34it/s]\n",
            "                   all       1043       1203      0.919      0.891       0.95      0.728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/34        13G     0.8394     0.7161      1.189         38        640: 100% 276/276 [03:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.33it/s]\n",
            "                   all       1043       1203      0.929      0.879      0.944      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/34        13G     0.8367     0.7001       1.19         30        640: 100% 276/276 [03:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.33it/s]\n",
            "                   all       1043       1203      0.917      0.881      0.945       0.73\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/34        13G     0.8263     0.6872      1.179         26        640: 100% 276/276 [03:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.34it/s]\n",
            "                   all       1043       1203      0.941      0.866      0.949      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/34        13G     0.8246     0.6754      1.176         28        640: 100% 276/276 [03:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.34it/s]\n",
            "                   all       1043       1203      0.917      0.892      0.949      0.731\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/34        13G     0.8064     0.6571      1.159         35        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.35it/s]\n",
            "                   all       1043       1203      0.927      0.883       0.95      0.735\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/34        13G     0.8096     0.6662      1.166         30        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.35it/s]\n",
            "                   all       1043       1203      0.934      0.895      0.954       0.74\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/34        13G     0.8009     0.6481      1.157         34        640: 100% 276/276 [03:53<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.35it/s]\n",
            "                   all       1043       1203      0.934      0.889      0.953      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/34        13G     0.8062     0.6499      1.167         28        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:24<00:00,  1.33it/s]\n",
            "                   all       1043       1203      0.944      0.891      0.952      0.745\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/34        13G     0.7936     0.6311       1.16         24        640: 100% 276/276 [03:52<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:25<00:00,  1.31it/s]\n",
            "                   all       1043       1203      0.938      0.901      0.958      0.747\n",
            "\n",
            "35 epochs completed in 2.538 hours.\n",
            "/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/utils/general.py:999: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x = torch.load(f, map_location=torch.device('cpu'))\n",
            "Optimizer stripped from /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_42/weights/last.pt, saved as /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_42/weights/last_striped.pt, 51.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_42/weights/best.pt, saved as /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_42/weights/best_striped.pt, 51.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_42/weights/best.pt...\n",
            "/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25228630 parameters, 0 gradients, 101.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:29<00:00,  1.10it/s]\n",
            "                   all       1043       1203      0.938      0.902      0.958      0.747\n",
            "                 knife       1043        601       0.93      0.909      0.957      0.709\n",
            "                pistol       1043        602      0.946      0.894      0.959      0.784\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_42\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST"
      ],
      "metadata": {
        "id": "hCwgf2-fD8ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "\n",
        "!python detect.py \\\n",
        "--imgsz 640 --device 0 \\\n",
        "--weights \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_4/weights/best.pt\" \\\n",
        "--source \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/test/images\" \\\n",
        "--conf-thres 0.5 \\\n",
        "--iou-thres 0.5 \\\n",
        "--project \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/results\" \\\n",
        "--name test_images\n",
        "\n",
        "# images are resized to 640x640\n",
        "# GPU device (0) is used\n",
        "# using the best weights from the previous training\n",
        "# detecting objects that the model believe to be knives/guns at least at 50%\n",
        "# if boxes overlap over 50%, the smaller one is not considered\n"
      ],
      "metadata": {
        "id": "C0nTcd11BMb5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the model on some short videos\n",
        "# here the model goes over every frame any tries to pick up guns/knives in every frame\n",
        "\n",
        "!python detect.py \\\n",
        "--imgsz 640 --device 0 \\\n",
        "--weights \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/training info/insights_4/weights/best.pt\" \\\n",
        "--source \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/data/video\" \\\n",
        "--conf-thres 0.5 \\\n",
        "--iou-thres 0.5 \\\n",
        "--project \"/content/drive/MyDrive/My projects/Guns & Knives YOLOv9/results\" \\\n",
        "--name test_videos\n",
        "\n",
        "# images are resized to 640x640\n",
        "# GPU device (0) is used\n",
        "# using the best weights from the previous training\n",
        "# detecting objects that the model believe to be knives/guns at least at 50%\n",
        "# if boxes overlap over 50%, the smaller one is not considered\n",
        "\n"
      ],
      "metadata": {
        "id": "JYR1_KX-JzxL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}